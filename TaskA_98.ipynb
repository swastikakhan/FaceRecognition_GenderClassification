{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOxkfQMOh0zwgWY6D7crPF9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swastikakhan/FaceRecognition_GenderClassification/blob/main/TaskA_98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTMbo5Ix7Qdt",
        "outputId": "b03a7043-cd4f-4d5d-f281-25c0fe8b8361"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Extracting dataset...\n",
            "Zip file exists: True\n",
            "Files in zip:\n",
            "  Comys_Hackathon5/\n",
            "  Comys_Hackathon5/Task_B/\n",
            "  Comys_Hackathon5/Task_A/\n",
            "  Comys_Hackathon5/Task_B/val/\n",
            "  Comys_Hackathon5/Task_B/train/\n",
            "  Comys_Hackathon5/Task_A/val/\n",
            "  Comys_Hackathon5/Task_A/train/\n",
            "  Comys_Hackathon5/Task_B/val/Jennifer_Keller/\n",
            "  Comys_Hackathon5/Task_B/val/Jennifer_Keller/Jennifer_Keller_0004.jpg\n",
            "  Comys_Hackathon5/Task_B/val/Jennifer_Keller/Jennifer_Keller_0003.jpg\n",
            "  ... and 23387 more files\n",
            "Dataset extracted successfully!\n",
            "\n",
            "Checking extracted contents:\n",
            "Comsys_Hackathon5 folder not found\n",
            "Contents of /content/:\n",
            "  .config\n",
            "  drive\n",
            "  face_recognition_svm.pkl\n",
            "  label_encoder.pkl\n",
            "  Comys_Hackathon5\n",
            "  sample_data\n",
            "Requirement already satisfied: facenet-pytorch in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch) (1.26.4)\n",
            "Requirement already satisfied: Pillow<10.3.0,>=10.2.0 in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch) (10.2.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch) (2.32.3)\n",
            "Requirement already satisfied: torch<2.3.0,>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch) (2.2.2)\n",
            "Requirement already satisfied: torchvision<0.18.0,>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch) (0.17.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2025.6.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3.0,>=2.2.0->facenet-pytorch) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<2.3.0,>=2.2.0->facenet-pytorch) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch<2.3.0,>=2.2.0->facenet-pytorch) (1.3.0)\n",
            "Using device: cuda\n",
            "Found dataset paths:\n",
            "Train dir: /content/Comys_Hackathon5/Task_A/train\n",
            "Val dir: /content/Comys_Hackathon5/Task_A/val\n",
            "Train dir exists: True\n",
            "Val dir exists: True\n",
            "Train dir contents: ['male', 'female']\n",
            "Val dir contents: ['male', 'female']\n",
            "Extracting train embeddings...\n",
            "Loading dataset from: /content/Comys_Hackathon5/Task_A/train\n",
            "Found 2 person folders\n",
            "  female: 394/394 faces detected\n",
            "  male: 1532/1532 faces detected\n",
            "Total: 1926 faces detected out of 1926 images\n",
            "Successfully processed: 2/2 folders\n",
            "Train dataset: 1926 samples\n",
            "Extracting val embeddings...\n",
            "Loading dataset from: /content/Comys_Hackathon5/Task_A/val\n",
            "Found 2 person folders\n",
            "  female: 105/105 faces detected\n",
            "  male: 317/317 faces detected\n",
            "Total: 422 faces detected out of 422 images\n",
            "Successfully processed: 2/2 folders\n",
            "Validation dataset: 422 samples\n",
            "Number of classes: 2\n",
            "Classes: ['female' 'male']\n",
            "Training multiple models...\n",
            "Final dataset shapes: X_train=(1926, 512), X_val=(422, 512)\n",
            "Number of classes: 2\n",
            "\n",
            "1. Training Linear SVM (balanced)...\n",
            "   Linear SVM Accuracy: 0.9194\n",
            "\n",
            "2. Training RBF SVM with GridSearch...\n",
            "   RBF SVM Accuracy: 0.9810\n",
            "   Best parameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 'scale'}\n",
            "\n",
            "3. Training Random Forest...\n",
            "   Random Forest Accuracy: 0.8341\n",
            "\n",
            "4. Training Neural Network...\n",
            "   Neural Network Accuracy: 0.9716\n",
            "\n",
            "🏆 Best Model: RBF SVM (Accuracy: 0.9810)\n",
            "\n",
            "Detailed Classification Report for RBF SVM:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      female       0.97      0.95      0.96       105\n",
            "        male       0.98      0.99      0.99       317\n",
            "\n",
            "    accuracy                           0.98       422\n",
            "   macro avg       0.98      0.97      0.97       422\n",
            "weighted avg       0.98      0.98      0.98       422\n",
            "\n",
            "\n",
            "Final Metrics:\n",
            "Accuracy: 0.9810\n",
            "Precision: 0.9810\n",
            "Recall: 0.9810\n",
            "F1-score: 0.9810\n",
            "\n",
            "Best model (RBF SVM) and label encoder saved!\n"
          ]
        }
      ],
      "source": [
        "# 1. Mount Google Drive and extract dataset\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Extract the dataset\n",
        "zip_path = '/content/drive/MyDrive/dataset2.zip'\n",
        "extract_path = '/content/'\n",
        "\n",
        "print(\"Extracting dataset...\")\n",
        "print(f\"Zip file exists: {os.path.exists(zip_path)}\")\n",
        "\n",
        "if not os.path.exists(zip_path):\n",
        "    print(\"ERROR: dataset2.zip not found in MyDrive!\")\n",
        "    print(\"Contents of MyDrive:\")\n",
        "    print(os.listdir('/content/drive/MyDrive/'))\n",
        "    exit()\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    print(\"Files in zip:\")\n",
        "    for file in zip_ref.namelist()[:10]:  # Show first 10 files\n",
        "        print(f\"  {file}\")\n",
        "    if len(zip_ref.namelist()) > 10:\n",
        "        print(f\"  ... and {len(zip_ref.namelist()) - 10} more files\")\n",
        "\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Dataset extracted successfully!\")\n",
        "\n",
        "# Check what was extracted\n",
        "print(\"\\nChecking extracted contents:\")\n",
        "if os.path.exists('/content/Comsys_Hackathon5'):\n",
        "    print(\"Found Comsys_Hackathon5 folder\")\n",
        "    print(\"Contents:\", os.listdir('/content/Comsys_Hackathon5'))\n",
        "\n",
        "    if os.path.exists('/content/Comsys_Hackathon5/Task_B'):\n",
        "        print(\"Found Task_B folder\")\n",
        "        print(\"Contents:\", os.listdir('/content/Comsys_Hackathon5/Task_B'))\n",
        "    else:\n",
        "        print(\"Task_B folder not found\")\n",
        "else:\n",
        "    print(\"Comsys_Hackathon5 folder not found\")\n",
        "    print(\"Contents of /content/:\")\n",
        "    for item in os.listdir('/content/'):\n",
        "        print(f\"  {item}\")\n",
        "        if os.path.isdir(f'/content/{item}') and 'Comsys' in item:\n",
        "            print(f\"    Contents of {item}:\", os.listdir(f'/content/{item}'))\n",
        "\n",
        "# 2. Install dependencies\n",
        "!pip install facenet-pytorch scikit-learn tqdm\n",
        "\n",
        "# 3. Imports\n",
        "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# 4. Setup models with better parameters\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# More aggressive face detection parameters\n",
        "mtcnn = MTCNN(\n",
        "    image_size=160,\n",
        "    margin=0,\n",
        "    min_face_size=20,  # Smaller minimum face size\n",
        "    thresholds=[0.4, 0.5, 0.5],  # More lenient thresholds\n",
        "    factor=0.709,  # Default scaling factor\n",
        "    post_process=True,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "facenet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
        "\n",
        "# 5. Helper: Extract face embedding with better preprocessing\n",
        "def get_embedding(img_path):\n",
        "    try:\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        # Check image size and resize if too small\n",
        "        if img.size[0] < 160 or img.size[1] < 160:\n",
        "            # Resize smaller images to minimum size\n",
        "            img = img.resize((max(160, img.size[0]), max(160, img.size[1])), Image.Resampling.LANCZOS)\n",
        "\n",
        "        # Try multiple detection strategies\n",
        "        face = None\n",
        "\n",
        "        # Strategy 1: Standard detection\n",
        "        face = mtcnn(img)\n",
        "\n",
        "        # Strategy 2: More lenient detection for difficult images\n",
        "        if face is None:\n",
        "            mtcnn_lenient = MTCNN(\n",
        "                image_size=160,\n",
        "                margin=0,\n",
        "                min_face_size=15,  # Even smaller\n",
        "                thresholds=[0.3, 0.4, 0.4],  # Very lenient\n",
        "                device=device\n",
        "            )\n",
        "            face = mtcnn_lenient(img)\n",
        "\n",
        "        # Strategy 3: Try with different image enhancements\n",
        "        if face is None:\n",
        "            # Enhance contrast for low-light/foggy images\n",
        "            from PIL import ImageEnhance\n",
        "            enhancer = ImageEnhance.Contrast(img)\n",
        "            enhanced_img = enhancer.enhance(2.0)  # Increase contrast\n",
        "            face = mtcnn(enhanced_img)\n",
        "\n",
        "        if face is None:\n",
        "            return None\n",
        "\n",
        "        # Normalize the face embedding (L2 normalization)\n",
        "        with torch.no_grad():\n",
        "            emb = facenet(face.unsqueeze(0).to(device))\n",
        "            emb = emb.squeeze().cpu().numpy()\n",
        "            # L2 normalize the embedding\n",
        "            emb = emb / np.linalg.norm(emb)\n",
        "\n",
        "        return emb\n",
        "    except Exception as e:\n",
        "        print(f\"      Error processing {img_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# 6. Prepare dataset with better error handling\n",
        "def load_dataset(folder):\n",
        "    X, y = [], []\n",
        "    print(f\"Loading dataset from: {folder}\")\n",
        "\n",
        "    if not os.path.exists(folder):\n",
        "        print(f\"Error: Folder {folder} does not exist!\")\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    total_images = 0\n",
        "    total_faces = 0\n",
        "    failed_folders = []\n",
        "\n",
        "    person_folders = sorted(os.listdir(folder))\n",
        "    print(f\"Found {len(person_folders)} person folders\")\n",
        "\n",
        "    for person in person_folders:\n",
        "        person_dir = os.path.join(folder, person)\n",
        "        if not os.path.isdir(person_dir):\n",
        "            continue\n",
        "\n",
        "        person_count = 0\n",
        "        person_images = 0\n",
        "\n",
        "        # Process all images in the person directory and subdirectories\n",
        "        for root, dirs, files in os.walk(person_dir):\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    img_path = os.path.join(root, file)\n",
        "                    person_images += 1\n",
        "                    total_images += 1\n",
        "\n",
        "                    emb = get_embedding(img_path)\n",
        "                    if emb is not None:\n",
        "                        X.append(emb)\n",
        "                        y.append(person)\n",
        "                        person_count += 1\n",
        "                        total_faces += 1\n",
        "\n",
        "        if person_count == 0:\n",
        "            failed_folders.append(person)\n",
        "        elif person_count > 0:\n",
        "            print(f\"  {person}: {person_count}/{person_images} faces detected\")\n",
        "\n",
        "    print(f\"Total: {total_faces} faces detected out of {total_images} images\")\n",
        "    print(f\"Successfully processed: {len(person_folders) - len(failed_folders)}/{len(person_folders)} folders\")\n",
        "\n",
        "    if len(failed_folders) > 0:\n",
        "        print(f\"Failed folders (no faces detected): {len(failed_folders)}\")\n",
        "        if len(failed_folders) <= 10:\n",
        "            print(f\"  Failed: {failed_folders}\")\n",
        "\n",
        "    if len(X) == 0:\n",
        "        print(\"ERROR: No face embeddings extracted!\")\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# 7. Set dataset paths - Find the correct paths dynamically\n",
        "def find_dataset_paths():\n",
        "    base_paths = [\n",
        "        '/content/Comsys_Hackathon5/Task_B',\n",
        "        '/content/dataset2/Comsys_Hackathon5/Task_B',\n",
        "        '/content/Task_B'\n",
        "    ]\n",
        "\n",
        "    # Check common extraction locations\n",
        "    for base_path in base_paths:\n",
        "        train_path = os.path.join(base_path, 'train')\n",
        "        val_path = os.path.join(base_path, 'val')\n",
        "\n",
        "        if os.path.exists(train_path) and os.path.exists(val_path):\n",
        "            return train_path, val_path\n",
        "\n",
        "    # If not found, search recursively\n",
        "    for root, dirs, files in os.walk('/content/'):\n",
        "        if 'train' in dirs and 'val' in dirs:\n",
        "            # Check if this looks like our dataset structure\n",
        "            train_path = os.path.join(root, 'train')\n",
        "            val_path = os.path.join(root, 'val')\n",
        "\n",
        "            # Quick check - should have subdirectories (person folders)\n",
        "            if os.path.exists(train_path) and os.path.exists(val_path):\n",
        "                train_subdirs = [d for d in os.listdir(train_path) if os.path.isdir(os.path.join(train_path, d))]\n",
        "                val_subdirs = [d for d in os.listdir(val_path) if os.path.isdir(os.path.join(val_path, d))]\n",
        "\n",
        "                if len(train_subdirs) > 0 and len(val_subdirs) > 0:\n",
        "                    return train_path, val_path\n",
        "\n",
        "    return None, None\n",
        "\n",
        "train_dir, val_dir = find_dataset_paths()\n",
        "\n",
        "if train_dir is None or val_dir is None:\n",
        "    print(\"ERROR: Could not find train and val directories!\")\n",
        "    print(\"Please check the dataset structure.\")\n",
        "    exit()\n",
        "\n",
        "print(f\"Found dataset paths:\")\n",
        "print(f\"Train dir: {train_dir}\")\n",
        "print(f\"Val dir: {val_dir}\")\n",
        "\n",
        "# Verify paths exist\n",
        "print(f\"Train dir exists: {os.path.exists(train_dir)}\")\n",
        "print(f\"Val dir exists: {os.path.exists(val_dir)}\")\n",
        "\n",
        "if os.path.exists(train_dir):\n",
        "    print(f\"Train dir contents: {os.listdir(train_dir)}\")\n",
        "if os.path.exists(val_dir):\n",
        "    print(f\"Val dir contents: {os.listdir(val_dir)}\")\n",
        "\n",
        "# 8. Load datasets\n",
        "print(\"Extracting train embeddings...\")\n",
        "X_train, y_train = load_dataset(train_dir)\n",
        "print(f\"Train dataset: {X_train.shape[0]} samples\")\n",
        "\n",
        "print(\"Extracting val embeddings...\")\n",
        "X_val, y_val = load_dataset(val_dir)\n",
        "print(f\"Validation dataset: {X_val.shape[0]} samples\")\n",
        "\n",
        "# Check if we have enough data\n",
        "if X_train.shape[0] == 0:\n",
        "    print(\"ERROR: No training samples found!\")\n",
        "    print(\"Possible issues:\")\n",
        "    print(\"1. No faces detected in training images\")\n",
        "    print(\"2. Wrong dataset structure\")\n",
        "    print(\"3. Image format issues\")\n",
        "\n",
        "    # Let's check what's actually in the directories\n",
        "    print(\"\\nDebugging - checking actual directory contents:\")\n",
        "    if os.path.exists(train_dir):\n",
        "        for person in os.listdir(train_dir):\n",
        "            person_dir = os.path.join(train_dir, person)\n",
        "            if os.path.isdir(person_dir):\n",
        "                files = [f for f in os.listdir(person_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "                print(f\"  {person}: {len(files)} image files\")\n",
        "                if len(files) > 0:\n",
        "                    print(f\"    Sample files: {files[:3]}\")  # Show first 3 files\n",
        "\n",
        "                    # Try to process one image manually for debugging\n",
        "                    sample_img = os.path.join(person_dir, files[0])\n",
        "                    print(f\"    Testing image: {sample_img}\")\n",
        "                    try:\n",
        "                        img = Image.open(sample_img).convert('RGB')\n",
        "                        print(f\"    Image size: {img.size}\")\n",
        "                        face = mtcnn(img)\n",
        "                        if face is None:\n",
        "                            print(\"    No face detected - image might be too small, blurry, or face not clearly visible\")\n",
        "                        else:\n",
        "                            print(f\"    Face tensor shape: {face.shape}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"    Error processing image: {e}\")\n",
        "\n",
        "                # Check distortion folder\n",
        "                distortion_dir = os.path.join(person_dir, 'distortion')\n",
        "                if os.path.exists(distortion_dir):\n",
        "                    distortion_files = [f for f in os.listdir(distortion_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "                    print(f\"    Distortion folder: {len(distortion_files)} files\")\n",
        "                    if len(distortion_files) > 0:\n",
        "                        print(f\"      Sample distortion files: {distortion_files[:3]}\")\n",
        "\n",
        "    exit()\n",
        "\n",
        "if X_val.shape[0] == 0:\n",
        "    print(\"ERROR: No validation samples found!\")\n",
        "    exit()\n",
        "\n",
        "# 9. Encode labels\n",
        "le = LabelEncoder()\n",
        "y_train_enc = le.fit_transform(y_train)\n",
        "y_val_enc = le.transform(y_val)\n",
        "\n",
        "print(f\"Number of classes: {len(le.classes_)}\")\n",
        "print(f\"Classes: {le.classes_}\")\n",
        "\n",
        "# 10. Train multiple models and choose the best\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import joblib\n",
        "\n",
        "print(\"Training multiple models...\")\n",
        "\n",
        "# Prepare data\n",
        "print(f\"Final dataset shapes: X_train={X_train.shape}, X_val={X_val.shape}\")\n",
        "print(f\"Number of classes: {len(le.classes_)}\")\n",
        "\n",
        "# Model 1: Linear SVM with class balancing\n",
        "print(\"\\n1. Training Linear SVM (balanced)...\")\n",
        "svm_linear = SVC(kernel='linear', probability=True, class_weight='balanced', C=1.0)\n",
        "svm_linear.fit(X_train, y_train_enc)\n",
        "y_pred_svm_linear = svm_linear.predict(X_val)\n",
        "acc_svm_linear = accuracy_score(y_val_enc, y_pred_svm_linear)\n",
        "print(f\"   Linear SVM Accuracy: {acc_svm_linear:.4f}\")\n",
        "\n",
        "# Model 2: RBF SVM with GridSearch\n",
        "print(\"\\n2. Training RBF SVM with GridSearch...\")\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1],\n",
        "    'class_weight': ['balanced', None]\n",
        "}\n",
        "svm_rbf = GridSearchCV(\n",
        "    SVC(kernel='rbf', probability=True),\n",
        "    param_grid,\n",
        "    cv=min(5, len(np.unique(y_train_enc))),  # Use fewer folds if few classes\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "svm_rbf.fit(X_train, y_train_enc)\n",
        "y_pred_svm_rbf = svm_rbf.predict(X_val)\n",
        "acc_svm_rbf = accuracy_score(y_val_enc, y_pred_svm_rbf)\n",
        "print(f\"   RBF SVM Accuracy: {acc_svm_rbf:.4f}\")\n",
        "print(f\"   Best parameters: {svm_rbf.best_params_}\")\n",
        "\n",
        "# Model 3: Random Forest\n",
        "print(\"\\n3. Training Random Forest...\")\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=None,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    class_weight='balanced',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf.fit(X_train, y_train_enc)\n",
        "y_pred_rf = rf.predict(X_val)\n",
        "acc_rf = accuracy_score(y_val_enc, y_pred_rf)\n",
        "print(f\"   Random Forest Accuracy: {acc_rf:.4f}\")\n",
        "\n",
        "# Model 4: Neural Network (MLP)\n",
        "print(\"\\n4. Training Neural Network...\")\n",
        "mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(512, 256, 128),\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    alpha=0.0001,\n",
        "    batch_size='auto',\n",
        "    learning_rate='adaptive',\n",
        "    max_iter=500,\n",
        "    random_state=42\n",
        ")\n",
        "mlp.fit(X_train, y_train_enc)\n",
        "y_pred_mlp = mlp.predict(X_val)\n",
        "acc_mlp = accuracy_score(y_val_enc, y_pred_mlp)\n",
        "print(f\"   Neural Network Accuracy: {acc_mlp:.4f}\")\n",
        "\n",
        "# Choose the best model\n",
        "models = {\n",
        "    'Linear SVM': (svm_linear, y_pred_svm_linear, acc_svm_linear),\n",
        "    'RBF SVM': (svm_rbf, y_pred_svm_rbf, acc_svm_rbf),\n",
        "    'Random Forest': (rf, y_pred_rf, acc_rf),\n",
        "    'Neural Network': (mlp, y_pred_mlp, acc_mlp)\n",
        "}\n",
        "\n",
        "best_model_name = max(models.keys(), key=lambda x: models[x][2])\n",
        "best_model, best_predictions, best_accuracy = models[best_model_name]\n",
        "\n",
        "print(f\"\\n🏆 Best Model: {best_model_name} (Accuracy: {best_accuracy:.4f})\")\n",
        "\n",
        "# Show detailed results for the best model\n",
        "print(f\"\\nDetailed Classification Report for {best_model_name}:\")\n",
        "print(classification_report(y_val_enc, best_predictions, target_names=le.classes_))\n",
        "\n",
        "print(f\"\\nFinal Metrics:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_val_enc, best_predictions):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_val_enc, best_predictions, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_val_enc, best_predictions, average='weighted'):.4f}\")\n",
        "print(f\"F1-score: {f1_score(y_val_enc, best_predictions, average='weighted'):.4f}\")\n",
        "\n",
        "# Save the best model\n",
        "joblib.dump(best_model, '/content/best_face_recognition_model.pkl')\n",
        "joblib.dump(le, '/content/label_encoder.pkl')\n",
        "print(f\"\\nBest model ({best_model_name}) and label encoder saved!\")"
      ]
    }
  ]
}